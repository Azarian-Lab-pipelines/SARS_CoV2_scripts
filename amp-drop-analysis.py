#!/usr/bin/env python3

# Import necessary modules
import re
import numpy as np
import pandas as pd
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt

# Check the modules that are most likely not present
try:
    from Bio import Seq, SeqIO
except ImportError as e:
    print(e)
    sys.exit(1)
    
try:
    from scipy.spatial.distance import hamming
except ImportError as e:
    print(e)

#################### Set up the argument parser ####################
import argparse as ap
parser = ap.ArgumentParser(description="""
Script to identify possible amplicon drop-out regions by checking whole genome sequences for possible
mutations in primer-binding regions. We recommend that the whole genome sequences provided are:
        1) Generated using a different primer kit or
        2) Generated by shotgun sequencing (RECOMMENDED)
""", formatter_class=ap.RawTextHelpFormatter)

parser.add_argument("-b", "--bed", dest="bed", required=True,
        help="Indicate the BED file for the amplicon kit of interest.")
parser.add_argument("-r", "--reference", dest="ref", required=True,
        help="""Indicate the reference file used for generating the primers.
NOTE: This is usually supplied in the same directory if using a pre-made primer kit.
if not, Google entry in Reference column of BED file and it should lead to genome""")
parser.add_argument("-c", "--consensus", dest="consensus", required=True,
        help="Indicate the FASTA or multi-FASTA containing the sequences of interest.")
parser.add_argument("--text-print", dest="text", action="store_true",
        help="""Option to print results without using colors. Colors only work well within terminal or IPYNB.
By preventing color output, you can pipe results into a text file neatly for futute viewing""")

args = parser.parse_args()


#################### Set up functions ####################

# Set up the colors for print-outs
class bcolors:
        MIS = '\033[2;30;41m' #RED
        RESET = '\033[0m' #RESET COLOR

def FindSeqs(f):
    """
    Function to pull sequences from the multi-FASTA
    """
    
    # Pull the sequences
    full_seqs = SeqIO.to_dict(SeqIO.parse(f, "fasta"))
    
    # Only return what we need; saves us time and memory later on anyways
    seqs = {}
    for k in full_seqs.keys():
        seqs[k] = str(full_seqs[k].seq)
    
    return seqs

def PullRef(f):
    """
    Function to pull the reference sequence from a FASTA; no header
    """
    
    # Pull the sequences
    seq = []
    
    for line in open(f, "r"):
        if not line.startswith(">"):
            seq.append(line.strip())

    return "".join(seq) # The final sequence will not have a header after it
    
    
def GetPrimerSeqs(x):
    """
    Function to pull the primer sequences using the reference sequence and the primer positions
    """
    
    # Get the forward primers first
    if "L" in x.name:
        return ref[x["PS"]:x["PE"]]
    
    # To get the reverse primers we need:
        # 1) PE:PS instead
        # 2) Take the reverse compliment
    elif "R" in x.name:
        seq = Seq.Seq(ref[x["PE"]:x["PS"]])
        # seq.reverse_complement() # Not necessary since it should be in primer TSV
        return str(seq)
    else:
        print("Err: Primer label is not in right format")
        return "Err"
    
    
def PrintAligns(r,q, text):
    """
    Function to print out the string alignments wtih colors
    """

    r = np.array(list(r))
    q = np.array(list(q))
    
    if not text:
        print(f"Ref: {''.join(r)}")
        print("Qry: " + "".join([f"{bcolors.MIS}{q[n]}{bcolors.RESET}" if _ == False \
            else q[n]
            for n,_ in enumerate(q == r)]))
        print()
    else:
        print("Ref: " + "".join([f"{r[n]}" if _ == False \
            else "*"
            for n,_ in enumerate(q == r)]))
        print("Qry: " + "".join([f"{q[n]}" if _ == False \
            else "*"
            for n,_ in enumerate(q == r)]))
        print()

def HammRatio(s1,s2):
    """
    Function to calculate the Hamming distance ratio (distance/len(string))
    """
    hamm = len([x for x in np.array(list(s1)) != np.array(list(s2)) if x])
    return 1 - hamm/len(s1)

def PrimerMatch(seq, hr_thresh = 0.8, text=None):
    """
    Function to find which primers may be implicated in amplicon drop-outs
    """
    
    mismatches = set() # to return a list of amplicons with no match
    partials = [] # List to return primers with high-quality partial matches
    
    l = 7 # kmer length
    
    for a in amp_df.index:
        if "L" in a:
            r,s,e = amp_df.loc[a, ["Seq", "PS", "PE"]]
        else:
            r,s,e = amp_df.loc[a, ["Seq", "PE", "PS"]]
            
        if re.search(r, seq):
            pass
        else:
            # If we cannot get a perfect match, try a greedy K-mer approach or try an exhaustive match if we make the kmers big enough
            # Generate the kmers
            kmers = [r[i:i+l] for i in range(0, len(r)-l)]
            matches = {} # Dict for exhaustive search (kmatch, lev_ratio)
            
            for n,kmer in enumerate(kmers):
                try:
                    span = re.search(kmer, seq).span()
                    kmatch = seq[span[0]-n:span[0]+len(r)-n] # Shift the slice by n to the left; as if we are extending string both ways
                    hr = HammRatio(r, kmatch) # Hamming ratio of kmer match vs reference primer
                    matches[kmatch] = [hr, span[0], n]

                except AttributeError:
                    pass
                
            if len(matches) == 0:
                # If we run out with no matches
                mismatches.add(a)
                        
            else:
                max_ratio = np.max([x[0] for x in matches.values()])
                
                if max_ratio > hr_thresh:
                    best_match = [k for k,v in matches.items() if v[0] == max_ratio][0] # Take first best match, usually only one anyways
                    print(f"Partial match for {a} starting at pos {matches[best_match][1]} -- reference primer at pos {s,e}")
                    print(f"Best Hamming ratio: {round(max_ratio,2)}")
                    PrintAligns(r, best_match, text)
                    partials.append(a)
                else:
                    print(f"No high quality matches for {a}\n")
                    mismatches.add(a)

    print(f"No matches or partial matches for primers:")
    [print(f"\t{n}) {a}") for n,a in enumerate(mismatches)]
   
    return [list(mismatches), partials]


#################### Import and prepare the BED file ####################
# Pull in the reference file first
ref = PullRef(args.ref)

bed = pd.read_csv(args.bed, sep="\t",
             header=None,
             names=["Ref", "PS", "PE", "Primer", "Pool"])

# Correct for different naming schemes
if type(bed.index[0]) != int:
    bed.reset_index(inplace=True)
    bed.drop("Pool", inplace=True, axis=1)
    bed.columns = ["Ref", "PS", "PE", "Primer", "Pool"]


bed["AmpliconLabel"] = bed.Primer.apply(lambda x:re.search("_\d+_\w", x).group().strip("_").upper())
bed["Amplicon"] = bed.Primer.apply(lambda x:int(re.search("_\d+_", x).group().strip("_")))

bed = bed.sort_values(by="Amplicon", ascending=True).reset_index(drop=True)

amp_df = bed[["PS", "PE", "AmpliconLabel"]].set_index("AmpliconLabel")

# Correct for stirng index starting at 0
amp_df["PS"] = amp_df.PS -1
amp_df["PE"] = amp_df.PE -1

# Get the primer sequences
amp_df["Seq"] = amp_df.apply(lambda x: GetPrimerSeqs(x),
            axis=1)


#################### Check the consensus sequences ####################
# Read in the sequences
seqs = FindSeqs(args.consensus)

res = {} # dict to store the results in
cols = ["Mismatches", "Partials"]

# Run the PrimerMatch function
for header in seqs.keys():
    print(f"\n\n>>>>{header}<<<<")
    res[header] = PrimerMatch(seqs[header], text=args.text)

mdf = pd.DataFrame.from_dict(res, orient="index",
                             columns = cols)


#################### Make the plot ####################
nons = []
mdf.Mismatches.apply(lambda x:nons.extend(x))

parts = []
mdf.Partials.apply(lambda x:parts.extend(x))

pdf = pd.concat([pd.DataFrame.from_dict(Counter(parts), orient="index", 
                      columns=["Partials"]), 
           pd.DataFrame.from_dict(Counter(nons), orient="index", 
                      columns=["NonMatches"])], axis=1).fillna(0)

# Sort by amplicon
pdf["Amplicon"] = pdf.apply(lambda x: int(x.name.split("_")[0]),
                            axis=1)
pdf.sort_values(by="Amplicon", ascending=True, inplace=True)

plt.style.use("ggplot")
plt.figure(figsize=(8,8))

plt.bar(x=pdf.index, height=pdf.Partials/len(seqs.keys())*100, 
        color="gold", edgecolor="k", linewidth=1,
       label="Partial match")
plt.bar(x=pdf.index, height=pdf.NonMatches/len(seqs.keys())*100, bottom=pdf.Partials/len(seqs.keys())*100,
        color="gray", edgecolor="k", linewidth=1,
       label="No match")

plt.legend(facecolor="white", edgecolor="k", frameon=True)

plt.ylim(0, 110)

plt.title("Counts of partial and non-matches for each primer")
plt.ylabel("Percent of samples")
plt.xlabel("Amplicon")

o = args.consensus.split("/")[-1].replace(f".{args.consensus.split('.')[-1]}", "-amplicon-check.png")
plt.savefig(o, dpi=200)

print(f"Amplicon drop-out plot saved as '{o}'")
